{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb5coyf9xlqnIIqWVrmyIp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanBustamante107517/lab02-lp/blob/main/Untitled33.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrXAj-2gH8bz",
        "outputId": "824c31a8-ce8a-47d9-f608-6661c154ad5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "breast_cancer_wisconsin_original = fetch_ucirepo(id=15)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = breast_cancer_wisconsin_original.data.features\n",
        "y = breast_cancer_wisconsin_original.data.targets\n",
        "\n",
        "# metadata\n",
        "print(breast_cancer_wisconsin_original.metadata)\n",
        "\n",
        "# variable information\n",
        "print(breast_cancer_wisconsin_original.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHgMsNUMIQp9",
        "outputId": "816e8178-e043-44c7-a75e-5c40e3170df6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 15, 'name': 'Breast Cancer Wisconsin (Original)', 'repository_url': 'https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original', 'data_url': 'https://archive.ics.uci.edu/static/public/15/data.csv', 'abstract': 'Original Wisconsin Breast Cancer Database', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 699, 'num_features': 9, 'feature_types': ['Integer'], 'demographics': [], 'target_col': ['Class'], 'index_col': ['Sample_code_number'], 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1990, 'last_updated': 'Sun Mar 10 2024', 'dataset_doi': '10.24432/C5HP4Z', 'creators': ['WIlliam Wolberg'], 'intro_paper': None, 'additional_info': {'summary': \"Samples arrive periodically as Dr. Wolberg reports his clinical cases. The database therefore reflects this chronological grouping of the data. This grouping information appears immediately below, having been removed from the data itself:\\r\\n\\r\\nGroup 1: 367 instances (January 1989)\\r\\nGroup 2:  70 instances (October 1989)\\r\\nGroup 3:  31 instances (February 1990)\\r\\nGroup 4:  17 instances (April 1990)\\r\\nGroup 5:  48 instances (August 1990)\\r\\nGroup 6:  49 instances (Updated January 1991)\\r\\nGroup 7:  31 instances (June 1991)\\r\\nGroup 8:  86 instances (November 1991)\\r\\n-----------------------------------------\\r\\nTotal:   699 points (as of the donated datbase on 15 July 1992)\\r\\n\\r\\nNote that the results summarized above in Past Usage refer to a dataset of size 369, while Group 1 has only 367 instances.  This is because it originally contained 369 instances; 2 were removed.  The following statements summarizes changes to the original Group 1's set of data:\\r\\n\\r\\n#####  Group 1 : 367 points: 200B 167M (January 1989)\\r\\n\\r\\n#####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805\\r\\n\\r\\n#####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record\\r\\n#####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial\\r\\n#####                  : Changed 0 to 1 in field 6 of sample 1219406\\r\\n#####                  : Changed 0 to 1 in field 8 of following sample:\\r\\n#####                  : 1182404,2,3,1,1,1,2,0,1,1,1\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1. Sample code number:            id number\\r\\n2. Clump Thickness:               1 - 10\\r\\n3. Uniformity of Cell Size:       1 - 10\\r\\n4. Uniformity of Cell Shape:      1 - 10\\r\\n5. Marginal Adhesion:             1 - 10\\r\\n6. Single Epithelial Cell Size:   1 - 10\\r\\n7. Bare Nuclei:                   1 - 10\\r\\n8. Bland Chromatin:               1 - 10\\r\\n9. Normal Nucleoli:               1 - 10\\r\\n10. Mitoses:                       1 - 10\\r\\n11. Class:                        (2 for benign, 4 for malignant)', 'citation': 'This breast cancer databases was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg.  If you publish results when using this database, then please include this information in your acknowledgements.  Also, please cite one or more of:\\n1. O. L. Mangasarian and W. H. Wolberg: \"Cancer diagnosis via linear programming\", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.\\n2. William H. Wolberg and O.L. Mangasarian: \"Multisurface method of pattern separation for medical diagnosis applied to breast cytology\", Proceedings of the National Academy of Sciences, U.S.A., Volume 87, December 1990, pp 9193-9196.\\n3. O. L. Mangasarian, R. Setiono, and W.H. Wolberg: \"Pattern recognition via linear programming: Theory and application to medical diagnosis\", in: \"Large-scale numerical optimization\", Thomas F. Coleman and Yuying Li, editors, SIAM Publications, Philadelphia 1990, pp 22-30.\\n4. K. P. Bennett & O. L. Mangasarian: \"Robust linear programming discrimination of two linearly inseparable sets\", Optimization Methods and Software 1, 1992, 23-34 (Gordon & Breach Science Publishers).'}}\n",
            "                           name     role         type demographic  \\\n",
            "0            Sample_code_number       ID  Categorical        None   \n",
            "1               Clump_thickness  Feature      Integer        None   \n",
            "2       Uniformity_of_cell_size  Feature      Integer        None   \n",
            "3      Uniformity_of_cell_shape  Feature      Integer        None   \n",
            "4             Marginal_adhesion  Feature      Integer        None   \n",
            "5   Single_epithelial_cell_size  Feature      Integer        None   \n",
            "6                   Bare_nuclei  Feature      Integer        None   \n",
            "7               Bland_chromatin  Feature      Integer        None   \n",
            "8               Normal_nucleoli  Feature      Integer        None   \n",
            "9                       Mitoses  Feature      Integer        None   \n",
            "10                        Class   Target       Binary        None   \n",
            "\n",
            "                  description units missing_values  \n",
            "0                        None  None             no  \n",
            "1                        None  None             no  \n",
            "2                        None  None             no  \n",
            "3                        None  None             no  \n",
            "4                        None  None             no  \n",
            "5                        None  None             no  \n",
            "6                        None  None            yes  \n",
            "7                        None  None             no  \n",
            "8                        None  None             no  \n",
            "9                        None  None             no  \n",
            "10  2 = benign, 4 = malignant  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# LETRA A: IV y split\n",
        "# ========================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargar datos\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\"\n",
        "cols = [\"ID\", \"Clump_Thickness\", \"Uniformity_Cell_Size\", \"Uniformity_Cell_Shape\",\n",
        "        \"Marginal_Adhesion\", \"Single_Epithelial_Cell_Size\", \"Bare_Nuclei\",\n",
        "        \"Bland_Chromatin\", \"Normal_Nucleoli\", \"Mitoses\", \"Class\"]\n",
        "df = pd.read_csv(url, names=cols)\n",
        "\n",
        "# Preprocesamiento\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "df[\"Bare_Nuclei\"] = pd.to_numeric(df[\"Bare_Nuclei\"])\n",
        "df.dropna(inplace=True)\n",
        "df.drop(\"ID\", axis=1, inplace=True)\n",
        "df[\"Class\"] = df[\"Class\"].replace({2: 0, 4: 1})  # 0: benigno, 1: maligno\n",
        "\n",
        "# Función para IV\n",
        "def calcular_iv(data, feature, target, bins=5):\n",
        "    df_ = data[[feature, target]].copy()\n",
        "    if df_[feature].dtype != 'object':\n",
        "        df_[feature] = pd.qcut(df_[feature], q=bins, duplicates='drop')\n",
        "    grouped = df_.groupby(feature, observed=False)[target].agg(['count', 'sum'])\n",
        "    grouped.columns = ['Total', 'Events']\n",
        "    grouped['NonEvents'] = grouped['Total'] - grouped['Events']\n",
        "    grouped['%Events'] = grouped['Events'] / grouped['Events'].sum()\n",
        "    grouped['%NonEvents'] = grouped['NonEvents'] / grouped['NonEvents'].sum()\n",
        "    grouped['WoE'] = np.log(grouped['%Events'] / grouped['%NonEvents']).replace([np.inf, -np.inf], 0)\n",
        "    grouped['IV'] = (grouped['%Events'] - grouped['%NonEvents']) * grouped['WoE']\n",
        "    return grouped['IV'].sum()\n",
        "\n",
        "# Calcular IV\n",
        "iv_scores = {}\n",
        "for col in df.columns.drop('Class'):\n",
        "    iv_scores[col] = round(calcular_iv(df, col, 'Class'), 4)\n",
        "\n",
        "# Filtrar variables con IV >= 0.1\n",
        "iv_df = pd.DataFrame.from_dict(iv_scores, orient='index', columns=['IV']).sort_values(by='IV', ascending=False)\n",
        "iv_df = iv_df[iv_df['IV'] >= 0.1]\n",
        "vars_utiles = iv_df.index.tolist()\n",
        "\n",
        "# Datos de entrada final\n",
        "X = df[vars_utiles]\n",
        "y = df[\"Class\"]\n",
        "\n",
        "# División 75% entrenamiento, 25% prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
      ],
      "metadata": {
        "id": "zKJgJSo0LWeu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# LETRA B: Regresión logística\n",
        "# ========================\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Estimación con statsmodels para obtener p-values\n",
        "X_train_const = sm.add_constant(X_train)  # Agrega constante (intercepto)\n",
        "logit_model = sm.Logit(y_train, X_train_const).fit()\n",
        "\n",
        "print(logit_model.summary())\n",
        "\n",
        "# Paso opcional: eliminar variables no significativas (p > 0.05)\n",
        "pvals = logit_model.pvalues.drop(\"const\")\n",
        "vars_significativas = pvals[pvals <= 0.05].index.tolist()\n",
        "\n",
        "# Reentrenar modelo con solo variables significativas\n",
        "X_train_sig = X_train[vars_significativas]\n",
        "X_test_sig = X_test[vars_significativas]\n",
        "\n",
        "# Modelo con scikit-learn\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train_sig, y_train)\n",
        "y_pred = clf.predict(X_test_sig)\n",
        "y_prob = clf.predict_proba(X_test_sig)[:, 1]\n",
        "\n",
        "# Métricas\n",
        "print(\"\\n=== Reporte de Clasificación ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A32zsy_EMeBk",
        "outputId": "f589a95d-12a1-4c68-a385-d5c7c17d87f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.076494\n",
            "         Iterations 9\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                  Class   No. Observations:                  512\n",
            "Model:                          Logit   Df Residuals:                      503\n",
            "Method:                           MLE   Df Model:                            8\n",
            "Date:                Thu, 01 May 2025   Pseudo R-squ.:                  0.8799\n",
            "Time:                        00:15:03   Log-Likelihood:                -39.165\n",
            "converged:                       True   LL-Null:                       -326.13\n",
            "Covariance Type:            nonrobust   LLR p-value:                9.428e-119\n",
            "===============================================================================================\n",
            "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------------\n",
            "const                          -9.6828      1.358     -7.133      0.000     -12.344      -7.022\n",
            "Uniformity_Cell_Size            0.0053      0.224      0.023      0.981      -0.434       0.444\n",
            "Bare_Nuclei                     0.4080      0.104      3.923      0.000       0.204       0.612\n",
            "Uniformity_Cell_Shape           0.3384      0.225      1.505      0.132      -0.102       0.779\n",
            "Bland_Chromatin                 0.5477      0.216      2.540      0.011       0.125       0.970\n",
            "Single_Epithelial_Cell_Size     0.0560      0.187      0.300      0.764      -0.310       0.422\n",
            "Clump_Thickness                 0.5313      0.157      3.381      0.001       0.223       0.839\n",
            "Marginal_Adhesion               0.1988      0.136      1.461      0.144      -0.068       0.466\n",
            "Normal_Nucleoli                 0.1618      0.126      1.279      0.201      -0.086       0.410\n",
            "===============================================================================================\n",
            "\n",
            "=== Reporte de Clasificación ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97       103\n",
            "           1       0.98      0.91      0.95        68\n",
            "\n",
            "    accuracy                           0.96       171\n",
            "   macro avg       0.96      0.95      0.96       171\n",
            "weighted avg       0.96      0.96      0.96       171\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[102   1]\n",
            " [  6  62]]\n",
            "AUC: 0.9905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# LETRA C: Modelo SVM\n",
        "# ========================\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Estandarización\n",
        "scaler = StandardScaler()\n",
        "X_train_sig_scaled = scaler.fit_transform(X_train_sig)\n",
        "X_test_sig_scaled = scaler.transform(X_test_sig)\n",
        "\n",
        "# Modelo SVM lineal con probabilidades\n",
        "svm_clf = SVC(kernel='linear', probability=True)\n",
        "svm_clf.fit(X_train_sig_scaled, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred_svm = svm_clf.predict(X_test_sig_scaled)\n",
        "y_prob_svm = svm_clf.predict_proba(X_test_sig_scaled)[:, 1]\n",
        "\n",
        "# Métricas\n",
        "print(\"\\n=== Reporte de Clasificación SVM ===\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "print(\"Matriz de Confusión SVM:\")\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "\n",
        "print(f\"AUC (SVM): {roc_auc_score(y_test, y_prob_svm):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUMyCrAUMn1l",
        "outputId": "6c595f1d-951c-4506-bcdc-aa08944a8cf0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Reporte de Clasificación SVM ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96       103\n",
            "           1       0.95      0.91      0.93        68\n",
            "\n",
            "    accuracy                           0.95       171\n",
            "   macro avg       0.95      0.94      0.94       171\n",
            "weighted avg       0.95      0.95      0.95       171\n",
            "\n",
            "Matriz de Confusión SVM:\n",
            "[[100   3]\n",
            " [  6  62]]\n",
            "AUC (SVM): 0.9902\n"
          ]
        }
      ]
    }
  ]
}